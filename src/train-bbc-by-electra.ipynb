{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a870e840-b8f1-4ec6-8142-2d1c4cc580f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ElectraConfig, ElectraTokenizer, ElectraModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a778ab-9878-430e-9578-408d09a9724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/bbc-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0baf48c-55fd-422c-9e8d-b254c0887f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['category']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e5755-a02c-437a-b6ce-5ac3b94c1c74",
   "metadata": {},
   "source": [
    "# prepare for Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f0d37b-7834-48f7-a62f-a81344b8380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf95ab9-9e02-4903-b0be-cca4eb14aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }\n",
    "\n",
    "class BbcDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931e18b-0f08-485a-b5cd-9f6b8ef0a4bd",
   "metadata": {},
   "source": [
    "# added Classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba503721-511d-431b-ac31-c7e68487ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(ElectraClassifier, self).__init__()\n",
    "        configuration = ElectraConfig()\n",
    "\n",
    "        self.electra = ElectraModel(configuration)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.electra(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b255209-866a-4a32-adbc-cc23c95b64e5",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f3eeeb-4408-45c7-8eb9-10476adf43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = BbcDataset(train_data), BbcDataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=32)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe0e7f-ab59-407d-a17f-1ba304501aa9",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29fe84dd-1d42-450d-8677-6c8e7a9e6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = BbcDataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=32)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            output = model(input_id, mask)\n",
    "                    \n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "            y_pred.extend(output.argmax(dim=1).cpu().data.numpy())\n",
    "            y_true.extend(test_label.cpu().data.numpy())\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556e6e0-6a40-40dc-bf96-3ad1b98b93f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f1d3b95-4eed-4e21-b813-fe41f8e4d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3267ccf2-6538-4922-8b68-938a6342921e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.75 GiB total capacity; 5.16 GiB already allocated; 52.69 MiB free; 5.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m ElectraClassifier()\n\u001b[1;32m      3\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m learning_rate)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cuda:\n\u001b[0;32m---> 16\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         criterion \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch-py3_8/lib/python3.8/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.75 GiB total capacity; 5.16 GiB already allocated; 52.69 MiB free; 5.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = ElectraClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425dd8d7-152f-4e5c-af02-027a6946aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
